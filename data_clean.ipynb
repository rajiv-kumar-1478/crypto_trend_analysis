{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e7dd648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bnb_news.csv', 'dogecoin_news.csv', 'usdt_news.csv', 'solana_news.csv', 'avalanche_news.csv', 'litecoin_news.csv', 'Chainlink_news.csv', 'Cardano_news.csv', 'Polkadot_news.csv']\n"
     ]
    }
   ],
   "source": [
    "print(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7d5847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_articles.csv\n",
      "binance-coin_articles.csv\n",
      "ethereum_articles.csv\n",
      "tether_articles.csv\n",
      "solana_articles.csv\n",
      "bitcoin_articles.csv\n",
      "doge_articles.csv\n",
      "avalanche_articles.csv\n",
      "chainlink_articles.csv\n",
      "polkadot_articles.csv\n"
     ]
    }
   ],
   "source": [
    "tag_urls = [\n",
    "    \"https://cointelegraph.com/ada-price-index\",\n",
    "    \"https://cointelegraph.com/binance-coin-price-index\",\n",
    "    \"https://cointelegraph.com/ethereum-price\",\n",
    "    \"https://cointelegraph.com/tether-price-index\",\n",
    "    \"https://cointelegraph.com/solana-price-index\",\n",
    "    \"https://cointelegraph.com/bitcoin-price\",\n",
    "    \"https://cointelegraph.com/doge-price-index\",\n",
    "    \"https://cointelegraph.com/avalanche-price-index\",\n",
    "    \"https://cointelegraph.com/chainlink-price-index\",\n",
    "    \"https://cointelegraph.com/polkadot-price-index\"\n",
    "]\n",
    "\n",
    "lst = []\n",
    "for i in tag_urls:\n",
    "    path = i.replace(\"https://cointelegraph.com/\", \"\").strip(\"/\")\n",
    "    tag = path.replace(\"-price-index\", \"\").replace(\"-price\", \"\")\n",
    "    lst.append(f\"{tag}_articles.csv\")\n",
    "    print(f\"{tag}_articles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36443783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated ada_articles.csv and saved to updated_csvs\\ada_articles.csv\n",
      "✅ Updated binance-coin_articles.csv and saved to updated_csvs\\binance-coin_articles.csv\n",
      "✅ Updated ethereum_articles.csv and saved to updated_csvs\\ethereum_articles.csv\n",
      "✅ Updated tether_articles.csv and saved to updated_csvs\\tether_articles.csv\n",
      "✅ Updated solana_articles.csv and saved to updated_csvs\\solana_articles.csv\n",
      "✅ Updated bitcoin_articles.csv and saved to updated_csvs\\bitcoin_articles.csv\n",
      "✅ Updated doge_articles.csv and saved to updated_csvs\\doge_articles.csv\n",
      "✅ Updated avalanche_articles.csv and saved to updated_csvs\\avalanche_articles.csv\n",
      "✅ Updated chainlink_articles.csv and saved to updated_csvs\\chainlink_articles.csv\n",
      "✅ Updated polkadot_articles.csv and saved to updated_csvs\\polkadot_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "\n",
    "# Create folder for updated CSVs\n",
    "output_folder = \"updated_csvs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to convert date to YYYY-MM-DD safely\n",
    "def parse_date_safe(date_str):\n",
    "    try:\n",
    "        return parser.parse(date_str).strftime('%Y-%m-%d')\n",
    "    except Exception:\n",
    "        return date_str\n",
    "\n",
    "# Process each file\n",
    "for file in lst:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = df['date'].apply(parse_date_safe)\n",
    "        else:\n",
    "            print(f\"'date' column not found in {file}\")\n",
    "        # Save to output folder\n",
    "        output_path = os.path.join(output_folder, file)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"✅ Updated {file} and saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5003b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be4afbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eth_news.csv', 'btc_news.csv', 'usdt_news.csv', 'xrp_news.csv', 'dogecoin_news.csv', 'usdt_news.csv', 'solana_news.csv', 'avalanche_news.csv', 'Chainlink_news.csv', 'Cardano_news.csv', 'Polkadot_news.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tag = [\"eth\",\"btc\",\"usdt\",\"xrp\", \"dogecoin\", \"usdt\", \"solana\", \"avalanche\", \"Chainlink\", \"Cardano\", \"Polkadot\"] \n",
    "lst1=[]\n",
    "for i in tag:\n",
    "    lst1.append(f\"{i}_news.csv\")\n",
    "print (lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "097da13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: eth_news.csv → processed_csvs\\eth_news.csv\n",
      "Processed: btc_news.csv → processed_csvs\\btc_news.csv\n",
      "Processed: usdt_news.csv → processed_csvs\\usdt_news.csv\n",
      "Processed: xrp_news.csv → processed_csvs\\xrp_news.csv\n",
      "Processed: dogecoin_news.csv → processed_csvs\\dogecoin_news.csv\n",
      "Processed: usdt_news.csv → processed_csvs\\usdt_news.csv\n",
      "Processed: solana_news.csv → processed_csvs\\solana_news.csv\n",
      "Processed: avalanche_news.csv → processed_csvs\\avalanche_news.csv\n",
      "Processed: Chainlink_news.csv → processed_csvs\\Chainlink_news.csv\n",
      "Processed: Cardano_news.csv → processed_csvs\\Cardano_news.csv\n",
      "Processed: Polkadot_news.csv → processed_csvs\\Polkadot_news.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names (just the names, not full paths)\n",
    "csv_files =lst1  # Add more filenames here as needed\n",
    "\n",
    "# Paths\n",
    "input_dir = \"\"\n",
    "output_dir = os.path.join(input_dir, \"processed_csvs\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for file_name in csv_files:\n",
    "    input_path = os.path.join(input_dir, file_name)\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "\n",
    "        # Ensure 'date' column exists\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"'date' column not found in {file_name}\")\n",
    "            continue\n",
    "\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Processed: {file_name} → {output_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c235c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eth_news.csv', 'btc_news.csv', 'usdt_news.csv', 'xrp_news.csv', 'dogecoin_news.csv', 'usdt_news.csv', 'solana_news.csv', 'avalanche_news.csv', 'Chainlink_news.csv', 'Cardano_news.csv', 'Polkadot_news.csv']\n"
     ]
    }
   ],
   "source": [
    "print(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c1981a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada_articles.csv', 'binance-coin_articles.csv', 'ethereum_articles.csv', 'tether_articles.csv', 'solana_articles.csv', 'bitcoin_articles.csv', 'doge_articles.csv', 'avalanche_articles.csv', 'chainlink_articles.csv', 'polkadot_articles.csv']\n"
     ]
    }
   ],
   "source": [
    "print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06913ce8",
   "metadata": {},
   "source": [
    "### merge two csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa9f71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved to: merged/merged_polkadot_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "file1 = \"processed_csvs/Polkadot_news.csv\"\n",
    "file2 = \"updated_csvs/polkadot_articles.csv\"\n",
    "\n",
    "# Load the CSV files\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Convert date column in df1 (already in YYYY-MM-DD or close)\n",
    "df1['date'] = pd.to_datetime(df1['date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Convert relative dates in df2 (e.g., '26 minutes ago') to today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "df2['date'] = today\n",
    "\n",
    "# Select only required columns\n",
    "df1_filtered = df1[['date', 'headline', 'summary']]\n",
    "df2_filtered = df2[['date', 'headline', 'summary']]\n",
    "\n",
    "# Concatenate both DataFrames\n",
    "merged_df = pd.concat([df1_filtered, df2_filtered], ignore_index=True)\n",
    "\n",
    "# Sort by date\n",
    "merged_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Save the result\n",
    "output_path = \"merged/merged_polkadot_articles.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merged file saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91696fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
